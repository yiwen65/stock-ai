# Phase 3: AI å¼•æ“ä¸ Agent ç³»ç»Ÿ

**ä¼˜å…ˆçº§**: ğŸ”´ é«˜
**çŠ¶æ€**: â¬œ å¾…å¼€å§‹
**é¢„è®¡å·¥ä½œé‡**: å¤§
**ä¾èµ–**: Phase 2 å®Œæˆ

---

## ä»»åŠ¡æ¸…å•

### â¬œ Task 1: LLM é›†æˆåŸºç¡€è®¾æ–½
**çŠ¶æ€**: å¾…å¼€å§‹
**æ–‡ä»¶**:
- åˆ›å»º: `backend/app/services/llm_service.py`
- åˆ›å»º: `backend/app/core/llm_config.py`
- ä¿®æ”¹: `backend/app/core/config.py`
- ä¿®æ”¹: `backend/requirements.txt`

**æ­¥éª¤**:

1. **æ·»åŠ  LLM ä¾èµ–**
   ```python
   # backend/requirements.txt
   openai==1.12.0
   langchain==0.1.6
   langchain-openai==0.0.5
   tiktoken==0.5.2
   ```

2. **é…ç½® LLM è®¾ç½®**
   ```python
   # backend/app/core/llm_config.py

   from pydantic_settings import BaseSettings

   class LLMSettings(BaseSettings):
       OPENAI_API_KEY: str
       OPENAI_MODEL: str = "gpt-4-turbo-preview"
       OPENAI_TEMPERATURE: float = 0.7
       OPENAI_MAX_TOKENS: int = 2000

       # DeepSeek é…ç½®ï¼ˆå¤‡é€‰ï¼‰
       DEEPSEEK_API_KEY: str = ""
       DEEPSEEK_BASE_URL: str = "https://api.deepseek.com/v1"

       class Config:
           env_file = ".env"
   ```

3. **å®ç° LLM æœåŠ¡**
   ```python
   # backend/app/services/llm_service.py

   from openai import AsyncOpenAI
   from typing import List, Dict, Optional

   class LLMService:
       def __init__(self, settings: LLMSettings):
           self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
           self.model = settings.OPENAI_MODEL
           self.temperature = settings.OPENAI_TEMPERATURE
           self.max_tokens = settings.OPENAI_MAX_TOKENS

       async def chat_completion(
           self,
           messages: List[Dict[str, str]],
           temperature: Optional[float] = None,
           max_tokens: Optional[int] = None
       ) -> str:
           """è°ƒç”¨ LLM ç”Ÿæˆå›å¤"""
           response = await self.client.chat.completions.create(
               model=self.model,
               messages=messages,
               temperature=temperature or self.temperature,
               max_tokens=max_tokens or self.max_tokens
           )
           return response.choices[0].message.content

       async def structured_output(
           self,
           messages: List[Dict[str, str]],
           response_format: Dict
       ) -> Dict:
           """è°ƒç”¨ LLM ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼ˆJSONï¼‰"""
           response = await self.client.chat.completions.create(
               model=self.model,
               messages=messages,
               response_format={"type": "json_object"},
               temperature=0.3  # é™ä½æ¸©åº¦ä»¥æé«˜ç»“æ„åŒ–è¾“å‡ºå‡†ç¡®æ€§
           )
           import json
           return json.loads(response.choices[0].message.content)
   ```

4. **æµ‹è¯• LLM è¿æ¥**
   ```python
   # backend/tests/unit/test_llm_service.py

   @pytest.mark.asyncio
   async def test_llm_chat_completion():
       llm_service = LLMService(settings)
       messages = [
           {"role": "system", "content": "You are a helpful assistant."},
           {"role": "user", "content": "Say hello"}
       ]
       response = await llm_service.chat_completion(messages)
       assert isinstance(response, str)
       assert len(response) > 0
   ```

5. **æäº¤ä»£ç **
   ```bash
   git add backend/app/services/llm_service.py backend/app/core/llm_config.py
   git commit -m "feat: add LLM service integration"
   ```

---

### â¬œ Task 2: è‡ªç„¶è¯­è¨€ç­–ç•¥è§£æå¼•æ“
**çŠ¶æ€**: å¾…å¼€å§‹
**æ–‡ä»¶**:
- åˆ›å»º: `backend/app/engines/strategy_parser.py`
- åˆ›å»º: `backend/app/schemas/strategy_parse.py`
- åˆ›å»º: `backend/tests/unit/test_strategy_parser.py`

**æ­¥éª¤**:

1. **è®¾è®¡ç­–ç•¥è§£æ Schema**
   ```python
   # backend/app/schemas/strategy_parse.py

   from pydantic import BaseModel
   from typing import List, Optional

   class StrategyParseRequest(BaseModel):
       description: str  # ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°

   class ParsedCondition(BaseModel):
       field: str
       operator: str
       value: float | List[float]
       description: str  # æ¡ä»¶çš„ä¸­æ–‡æè¿°

   class StrategyParseResponse(BaseModel):
       conditions: List[ParsedCondition]
       logic: str  # "AND" or "OR"
       conflicts: List[str]  # é€»è¾‘å†²çªæç¤º
       confidence: float  # è§£æç½®ä¿¡åº¦ (0-1)
       summary: str  # ç­–ç•¥æ€»ç»“
   ```

2. **å®ç°ç­–ç•¥è§£æå¼•æ“**
   ```python
   # backend/app/engines/strategy_parser.py

   class StrategyParser:
       def __init__(self, llm_service: LLMService):
           self.llm_service = llm_service

       async def parse(self, description: str) -> StrategyParseResponse:
           """è§£æè‡ªç„¶è¯­è¨€ç­–ç•¥æè¿°"""
           # 1. æ„å»º Prompt
           prompt = self._build_parse_prompt(description)

           # 2. è°ƒç”¨ LLM
           messages = [
               {"role": "system", "content": self._get_system_prompt()},
               {"role": "user", "content": prompt}
           ]

           response = await self.llm_service.structured_output(
               messages=messages,
               response_format={"type": "json_object"}
           )

           # 3. éªŒè¯å’Œè½¬æ¢
           parsed = self._validate_and_convert(response)

           # 4. æ£€æµ‹é€»è¾‘å†²çª
           conflicts = self._detect_conflicts(parsed['conditions'])

           return StrategyParseResponse(
               conditions=parsed['conditions'],
               logic=parsed['logic'],
               conflicts=conflicts,
               confidence=parsed.get('confidence', 0.8),
               summary=parsed.get('summary', '')
           )

       def _get_system_prompt(self) -> str:
           """ç³»ç»Ÿæç¤ºè¯"""
           return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Aè‚¡é€‰è‚¡ç­–ç•¥è§£æåŠ©æ‰‹ã€‚

   ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–çš„é€‰è‚¡æ¡ä»¶ã€‚

   æ”¯æŒçš„å­—æ®µï¼š
   - ä¼°å€¼æŒ‡æ ‡: pe (å¸‚ç›ˆç‡), pb (å¸‚å‡€ç‡), ps (å¸‚é”€ç‡)
   - ç›ˆåˆ©æŒ‡æ ‡: roe (å‡€èµ„äº§æ”¶ç›Šç‡), roa (æ€»èµ„äº§æ”¶ç›Šç‡), net_margin (å‡€åˆ©ç‡)
   - æˆé•¿æŒ‡æ ‡: revenue_growth (è¥æ”¶å¢é•¿ç‡), profit_growth (å‡€åˆ©æ¶¦å¢é•¿ç‡)
   - è´¢åŠ¡å¥åº·: debt_ratio (èµ„äº§è´Ÿå€ºç‡), current_ratio (æµåŠ¨æ¯”ç‡)
   - å¸‚å€¼: market_cap (æ€»å¸‚å€¼)

   æ”¯æŒçš„è¿ç®—ç¬¦: <, >, <=, >=, ==, between

   è¾“å‡º JSON æ ¼å¼ï¼š
   {
     "conditions": [
       {"field": "pe", "operator": "<", "value": 15, "description": "å¸‚ç›ˆç‡å°äº15"},
       ...
     ],
     "logic": "AND",
     "confidence": 0.9,
     "summary": "å¯»æ‰¾ä½ä¼°å€¼ã€é«˜ç›ˆåˆ©çš„ä»·å€¼è‚¡"
   }
   """

       def _build_parse_prompt(self, description: str) -> str:
           """æ„å»ºè§£ææç¤º"""
           return f"""è¯·è§£æä»¥ä¸‹é€‰è‚¡ç­–ç•¥æè¿°ï¼š

   "{description}"

   è¯·è¾“å‡ºç»“æ„åŒ–çš„ç­›é€‰æ¡ä»¶ã€‚"""

       def _validate_and_convert(self, response: Dict) -> Dict:
           """éªŒè¯å’Œè½¬æ¢ LLM è¾“å‡º"""
           # éªŒè¯å­—æ®µåˆæ³•æ€§
           valid_fields = {
               'pe', 'pb', 'ps', 'roe', 'roa', 'net_margin',
               'revenue_growth', 'profit_growth', 'debt_ratio',
               'current_ratio', 'market_cap'
           }

           for condition in response['conditions']:
               if condition['field'] not in valid_fields:
                   raise ValueError(f"Invalid field: {condition['field']}")

           return response

       def _detect_conflicts(self, conditions: List[Dict]) -> List[str]:
           """æ£€æµ‹é€»è¾‘å†²çª"""
           conflicts = []

           # æ£€æµ‹åŒä¸€å­—æ®µçš„å†²çªæ¡ä»¶
           field_conditions = {}
           for cond in conditions:
               field = cond['field']
               if field not in field_conditions:
                   field_conditions[field] = []
               field_conditions[field].append(cond)

           for field, conds in field_conditions.items():
               if len(conds) > 1:
                   # æ£€æŸ¥æ˜¯å¦æœ‰å†²çªï¼ˆå¦‚ pe < 10 ä¸” pe > 20ï¼‰
                   if self._has_conflict(conds):
                       conflicts.append(f"{field} å­˜åœ¨å†²çªæ¡ä»¶")

           return conflicts

       def _has_conflict(self, conditions: List[Dict]) -> bool:
           """æ£€æŸ¥æ¡ä»¶æ˜¯å¦å†²çª"""
           # ç®€åŒ–ç‰ˆï¼šæ£€æŸ¥ < å’Œ > çš„å†²çª
           has_lt = any(c['operator'] in ['<', '<='] for c in conditions)
           has_gt = any(c['operator'] in ['>', '>='] for c in conditions)

           if has_lt and has_gt:
               lt_val = next(c['value'] for c in conditions if c['operator'] in ['<', '<='])
               gt_val = next(c['value'] for c in conditions if c['operator'] in ['>', '>='])
               return gt_val >= lt_val

           return False
   ```

3. **ç¼–å†™æµ‹è¯•ç”¨ä¾‹**
   ```python
   # backend/tests/unit/test_strategy_parser.py

   @pytest.mark.asyncio
   async def test_parse_graham_strategy():
       parser = StrategyParser(llm_service)
       description = "å¯»æ‰¾å¸‚ç›ˆç‡å°äº15ã€å¸‚å‡€ç‡å°äº2ã€èµ„äº§è´Ÿå€ºç‡å°äº60%çš„ä»·å€¼è‚¡"

       result = await parser.parse(description)

       assert len(result.conditions) == 3
       assert any(c.field == 'pe' and c.operator == '<' and c.value == 15 for c in result.conditions)
       assert result.logic == "AND"
       assert len(result.conflicts) == 0
   ```

4. **åˆ›å»ºç­–ç•¥è§£æ API**
   ```python
   # backend/app/api/v1/strategy.py (æ·»åŠ ç«¯ç‚¹)

   @router.post("/parse", response_model=StrategyParseResponse)
   async def parse_strategy(request: StrategyParseRequest):
       """è§£æè‡ªç„¶è¯­è¨€ç­–ç•¥æè¿°"""
       parser = StrategyParser(llm_service)
       result = await parser.parse(request.description)
       return result
   ```

5. **æäº¤ä»£ç **
   ```bash
   git add backend/app/engines/strategy_parser.py backend/app/schemas/strategy_parse.py
   git commit -m "feat: add natural language strategy parser"
   ```

---

### â¬œ Task 3: Multi-Agent æ¶æ„åŸºç¡€
**çŠ¶æ€**: å¾…å¼€å§‹
**æ–‡ä»¶**:
- åˆ›å»º: `backend/app/agents/base_agent.py`
- åˆ›å»º: `backend/app/agents/orchestrator.py`
- åˆ›å»º: `backend/tests/unit/test_agents.py`

**æ­¥éª¤**:

1. **è®¾è®¡ Agent åŸºç±»**
   ```python
   # backend/app/agents/base_agent.py

   from abc import ABC, abstractmethod
   from typing import Dict, Any

   class BaseAgent(ABC):
       """Agent åŸºç±»"""

       def __init__(self, llm_service: LLMService, name: str):
           self.llm_service = llm_service
           self.name = name

       @abstractmethod
       async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
           """æ‰§è¡Œ Agent ä»»åŠ¡"""
           pass

       def _build_prompt(self, context: Dict[str, Any]) -> str:
           """æ„å»ºæç¤ºè¯"""
           pass

       async def _call_llm(self, prompt: str) -> str:
           """è°ƒç”¨ LLM"""
           messages = [
               {"role": "system", "content": self._get_system_prompt()},
               {"role": "user", "content": prompt}
           ]
           return await self.llm_service.chat_completion(messages)

       @abstractmethod
       def _get_system_prompt(self) -> str:
           """è·å–ç³»ç»Ÿæç¤ºè¯"""
           pass
   ```

2. **å®ç° Orchestrator Agent**
   ```python
   # backend/app/agents/orchestrator.py

   class OrchestratorAgent:
       """ä¸»æ§ Agentï¼šåè°ƒå¤šä¸ªä¸“ä¸š Agent"""

       def __init__(
           self,
           llm_service: LLMService,
           data_agent: 'DataAgent',
           fundamental_agent: 'FundamentalAgent',
           technical_agent: 'TechnicalAgent',
           evaluator_agent: 'EvaluatorAgent'
       ):
           self.llm_service = llm_service
           self.data_agent = data_agent
           self.fundamental_agent = fundamental_agent
           self.technical_agent = technical_agent
           self.evaluator_agent = evaluator_agent

       async def analyze_stock(self, stock_code: str) -> Dict:
           """åè°ƒå¤šä¸ª Agent åˆ†æè‚¡ç¥¨"""
           # 1. Data Agent è·å–æ•°æ®
           data = await self.data_agent.execute({'stock_code': stock_code})

           # 2. å¹¶è¡Œæ‰§è¡Œåˆ†æ Agents
           import asyncio
           fundamental_task = self.fundamental_agent.execute(data)
           technical_task = self.technical_agent.execute(data)

           fundamental_result, technical_result = await asyncio.gather(
               fundamental_task,
               technical_task
           )

           # 3. Evaluator Agent ç»¼åˆè¯„ä¼°
           evaluation = await self.evaluator_agent.execute({
               'stock_code': stock_code,
               'fundamental': fundamental_result,
               'technical': technical_result
           })

           return evaluation
   ```

3. **æäº¤ä»£ç **
   ```bash
   git add backend/app/agents/
   git commit -m "feat: add multi-agent architecture foundation"
   ```

---

### â¬œ Task 4: ä¸“ä¸šåˆ†æ Agents
**çŠ¶æ€**: å¾…å¼€å§‹
**æ–‡ä»¶**:
- åˆ›å»º: `backend/app/agents/data_agent.py`
- åˆ›å»º: `backend/app/agents/fundamental_agent.py`
- åˆ›å»º: `backend/app/agents/technical_agent.py`
- åˆ›å»º: `backend/app/agents/evaluator_agent.py`

**æ­¥éª¤**:

1. **å®ç° Data Agent**
   ```python
   # backend/app/agents/data_agent.py

   class DataAgent(BaseAgent):
       """æ•°æ®è·å– Agent"""

       async def execute(self, context: Dict) -> Dict:
           stock_code = context['stock_code']

           # å¹¶è¡Œè·å–æ•°æ®
           import asyncio
           realtime_task = self._get_realtime_data(stock_code)
           kline_task = self._get_kline_data(stock_code)
           financial_task = self._get_financial_data(stock_code)

           realtime, kline, financial = await asyncio.gather(
               realtime_task, kline_task, financial_task
           )

           return {
               'stock_code': stock_code,
               'realtime': realtime,
               'kline': kline,
               'financial': financial
           }
   ```

2. **å®ç° Fundamental Agent**
   ```python
   # backend/app/agents/fundamental_agent.py

   class FundamentalAgent(BaseAgent):
       """åŸºæœ¬é¢åˆ†æ Agent"""

       def _get_system_prompt(self) -> str:
           return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŸºæœ¬é¢åˆ†æå¸ˆã€‚

   ä½ çš„ä»»åŠ¡æ˜¯åˆ†æè‚¡ç¥¨çš„åŸºæœ¬é¢ï¼ŒåŒ…æ‹¬ï¼š
   1. ä¼°å€¼æ°´å¹³ï¼ˆPEã€PBã€PSï¼‰
   2. ç›ˆåˆ©èƒ½åŠ›ï¼ˆROEã€ROAã€å‡€åˆ©ç‡ï¼‰
   3. æˆé•¿æ€§ï¼ˆè¥æ”¶å¢é•¿ã€åˆ©æ¶¦å¢é•¿ï¼‰
   4. è´¢åŠ¡å¥åº·ï¼ˆè´Ÿå€ºç‡ã€æµåŠ¨æ¯”ç‡ã€ç°é‡‘æµï¼‰

   è¯·ç»™å‡ºï¼š
   - å„ç»´åº¦è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
   - ä¼˜åŠ¿å’Œé£é™©ç‚¹
   - æŠ•èµ„å»ºè®®
   """

       async def execute(self, context: Dict) -> Dict:
           # æ„å»ºåˆ†ææç¤º
           prompt = self._build_analysis_prompt(context)

           # è°ƒç”¨ LLM åˆ†æ
           analysis = await self._call_llm(prompt)

           return {
               'agent': 'fundamental',
               'analysis': analysis,
               'score': self._extract_score(analysis)
           }
   ```

3. **å®ç° Technical Agent**
   ```python
   # backend/app/agents/technical_agent.py

   class TechnicalAgent(BaseAgent):
       """æŠ€æœ¯é¢åˆ†æ Agent"""

       def _get_system_prompt(self) -> str:
           return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åˆ†æå¸ˆã€‚

   ä½ çš„ä»»åŠ¡æ˜¯åˆ†æè‚¡ç¥¨çš„æŠ€æœ¯é¢ï¼ŒåŒ…æ‹¬ï¼š
   1. è¶‹åŠ¿åˆ¤æ–­ï¼ˆä¸Šæ¶¨/ä¸‹è·Œ/éœ‡è¡ï¼‰
   2. æŠ€æœ¯æŒ‡æ ‡ï¼ˆMAã€MACDã€RSIã€KDJï¼‰
   3. æ”¯æ’‘ä½å’Œå‹åŠ›ä½
   4. ä¹°å–æ—¶æœº

   è¯·ç»™å‡ºï¼š
   - æŠ€æœ¯é¢è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
   - å…³é”®æŠ€æœ¯ä¿¡å·
   - æ“ä½œå»ºè®®
   """

       async def execute(self, context: Dict) -> Dict:
           prompt = self._build_analysis_prompt(context)
           analysis = await self._call_llm(prompt)

           return {
               'agent': 'technical',
               'analysis': analysis,
               'score': self._extract_score(analysis)
           }
   ```

4. **å®ç° Evaluator Agent**
   ```python
   # backend/app/agents/evaluator_agent.py

   class EvaluatorAgent(BaseAgent):
       """ç»¼åˆè¯„ä¼° Agent"""

       def _get_system_prompt(self) -> str:
           return """ä½ æ˜¯ä¸€ä¸ªèµ„æ·±æŠ•èµ„é¡¾é—®ã€‚

   ä½ çš„ä»»åŠ¡æ˜¯ç»¼åˆåŸºæœ¬é¢å’ŒæŠ€æœ¯é¢åˆ†æï¼Œç»™å‡ºï¼š
   1. ç»¼åˆè¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
   2. é£é™©ç­‰çº§ï¼ˆä½/ä¸­/é«˜ï¼‰
   3. æŠ•èµ„å»ºè®®ï¼ˆä¹°å…¥/æŒæœ‰/è§‚æœ›/å–å‡ºï¼‰
   4. æ ¸å¿ƒç†ç”±ï¼ˆ3-5æ¡ï¼‰

   è¯·åŸºäºå¤šç»´åº¦åˆ†æç»™å‡ºå®¢è§‚ã€ä¸“ä¸šçš„æŠ•èµ„å»ºè®®ã€‚
   """

       async def execute(self, context: Dict) -> Dict:
           prompt = f"""
   è‚¡ç¥¨ä»£ç : {context['stock_code']}

   åŸºæœ¬é¢åˆ†æ:
   {context['fundamental']['analysis']}
   è¯„åˆ†: {context['fundamental']['score']}/10

   æŠ€æœ¯é¢åˆ†æ:
   {context['technical']['analysis']}
   è¯„åˆ†: {context['technical']['score']}/10

   è¯·ç»™å‡ºç»¼åˆè¯„ä¼°ã€‚
   """

           evaluation = await self._call_llm(prompt)

           return {
               'overall_score': self._extract_score(evaluation),
               'risk_level': self._extract_risk_level(evaluation),
               'recommendation': self._extract_recommendation(evaluation),
               'summary': evaluation
           }
   ```

5. **æäº¤ä»£ç **
   ```bash
   git add backend/app/agents/
   git commit -m "feat: implement specialized analysis agents"
   ```

---

### â¬œ Task 5: RAG ç³»ç»Ÿï¼ˆå‘é‡æ£€ç´¢ï¼‰
**çŠ¶æ€**: å¾…å¼€å§‹
**æ–‡ä»¶**:
- åˆ›å»º: `backend/app/services/vector_service.py`
- åˆ›å»º: `backend/app/services/embedding_service.py`
- ä¿®æ”¹: `backend/requirements.txt`

**æ­¥éª¤**:

1. **æ·»åŠ ä¾èµ–**
   ```python
   # backend/requirements.txt
   qdrant-client==1.7.0
   sentence-transformers==2.3.1
   ```

2. **å®ç° Embedding æœåŠ¡**
   ```python
   # backend/app/services/embedding_service.py

   from openai import AsyncOpenAI

   class EmbeddingService:
       def __init__(self, api_key: str):
           self.client = AsyncOpenAI(api_key=api_key)
           self.model = "text-embedding-3-small"

       async def embed_text(self, text: str) -> List[float]:
           """ç”Ÿæˆæ–‡æœ¬å‘é‡"""
           response = await self.client.embeddings.create(
               model=self.model,
               input=text
           )
           return response.data[0].embedding

       async def embed_batch(self, texts: List[str]) -> List[List[float]]:
           """æ‰¹é‡ç”Ÿæˆå‘é‡"""
           response = await self.client.embeddings.create(
               model=self.model,
               input=texts
           )
           return [item.embedding for item in response.data]
   ```

3. **å®ç°å‘é‡æ£€ç´¢æœåŠ¡**
   ```python
   # backend/app/services/vector_service.py

   from qdrant_client import QdrantClient
   from qdrant_client.models import Distance, VectorParams, PointStruct

   class VectorService:
       def __init__(self, host: str = "localhost", port: int = 6333):
           self.client = QdrantClient(host=host, port=port)
           self.embedding_service = EmbeddingService(settings.OPENAI_API_KEY)

       async def create_collection(self, collection_name: str, vector_size: int = 1536):
           """åˆ›å»ºå‘é‡é›†åˆ"""
           self.client.create_collection(
               collection_name=collection_name,
               vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
           )

       async def add_documents(
           self,
           collection_name: str,
           documents: List[Dict]
       ):
           """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“"""
           # ç”Ÿæˆå‘é‡
           texts = [doc['content'] for doc in documents]
           vectors = await self.embedding_service.embed_batch(texts)

           # æ„å»º Points
           points = [
               PointStruct(
                   id=i,
                   vector=vector,
                   payload=doc
               )
               for i, (vector, doc) in enumerate(zip(vectors, documents))
           ]

           # æ’å…¥å‘é‡åº“
           self.client.upsert(
               collection_name=collection_name,
               points=points
           )

       async def search(
           self,
           collection_name: str,
           query: str,
           limit: int = 10,
           filters: Dict = None
       ) -> List[Dict]:
           """è¯­ä¹‰æœç´¢"""
           # ç”ŸæˆæŸ¥è¯¢å‘é‡
           query_vector = await self.embedding_service.embed_text(query)

           # å‘é‡æ£€ç´¢
           results = self.client.search(
               collection_name=collection_name,
               query_vector=query_vector,
               limit=limit,
               query_filter=filters
           )

           return [
               {
                   'score': result.score,
                   'payload': result.payload
               }
               for result in results
           ]
   ```

4. **æäº¤ä»£ç **
   ```bash
   git add backend/app/services/vector_service.py backend/app/services/embedding_service.py
   git commit -m "feat: add RAG system with vector search"
   ```

---

### â¬œ Task 6: AI åˆ†æ API é›†æˆ
**çŠ¶æ€**: å¾…å¼€å§‹
**æ–‡ä»¶**:
- ä¿®æ”¹: `backend/app/api/v1/analysis.py`
- åˆ›å»º: `backend/tests/integration/test_ai_analysis.py`

**æ­¥éª¤**:

1. **æ·»åŠ  AI å¢å¼ºåˆ†æç«¯ç‚¹**
   ```python
   # backend/app/api/v1/analysis.py

   @router.post("/{stock_code}/ai-analyze", response_model=AIAnalysisReport)
   async def ai_analyze_stock(stock_code: str):
       """ä½¿ç”¨ AI Agent ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š"""
       orchestrator = OrchestratorAgent(
           llm_service=llm_service,
           data_agent=DataAgent(llm_service),
           fundamental_agent=FundamentalAgent(llm_service),
           technical_agent=TechnicalAgent(llm_service),
           evaluator_agent=EvaluatorAgent(llm_service)
       )

       result = await orchestrator.analyze_stock(stock_code)
       return result
   ```

2. **æµ‹è¯• AI åˆ†æ**
   ```bash
   curl -X POST http://localhost:8000/api/v1/stocks/600519/ai-analyze | jq
   ```

3. **æäº¤ä»£ç **
   ```bash
   git add backend/app/api/v1/analysis.py
   git commit -m "feat: integrate AI agents into analysis API"
   ```

---

## å®Œæˆæ ‡å‡†

Phase 3 å®Œæˆåï¼ŒAI å¼•æ“åº”å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š

### åŠŸèƒ½å®Œæ•´æ€§
- âœ… LLM é›†æˆï¼ˆOpenAI/DeepSeekï¼‰
- âœ… è‡ªç„¶è¯­è¨€ç­–ç•¥è§£æ
- âœ… Multi-Agent æ¶æ„
- âœ… ä¸“ä¸šåˆ†æ Agentsï¼ˆData, Fundamental, Technical, Evaluatorï¼‰
- âœ… RAG å‘é‡æ£€ç´¢ç³»ç»Ÿ
- âœ… AI å¢å¼ºåˆ†æ API

### è´¨é‡æ ‡å‡†
- âœ… ç­–ç•¥è§£æå‡†ç¡®ç‡ > 85%
- âœ… Agent åˆ†æè´¨é‡é«˜
- âœ… å‘é‡æ£€ç´¢ç›¸å…³æ€§å¥½

### æ€§èƒ½æ ‡å‡†
- âœ… ç­–ç•¥è§£æå“åº” < 3s
- âœ… AI åˆ†æå“åº” < 10s
- âœ… å‘é‡æ£€ç´¢å“åº” < 500ms

---

## ä¸‹ä¸€æ­¥

å®Œæˆ Phase 3 åï¼Œè¿›å…¥ **Phase 4: æ•°æ®åŒæ­¥ç³»ç»Ÿ**

å‚è€ƒæ–‡æ¡£: `docs/tasks/phase-4-data-sync.md`
